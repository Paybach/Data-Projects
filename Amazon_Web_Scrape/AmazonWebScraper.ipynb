{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries for web scraping, data handling, and email sending\n",
    "from bs4 import BeautifulSoup  # Web Scraping library for pulling the data out of HTML and XML files\n",
    "import requests  # Allows sending HTTP requests using Python\n",
    "import smtplib  # Allows sending emails\n",
    "import time  # Provides various time-related functions\n",
    "import datetime  # Provides classes for manipulating dates and times\n",
    "import pandas as pd  # Provides data structures and data analysis tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling data from amazon\n",
    "How: Inspect the html of the page and find the element that contains the data we want (Ctrl + Shift + C) allows to select relevant element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Amazon product page to scrape\n",
    "URL = 'https://www.amazon.co.uk/Playstation-711719577157-PlayStation-Console-Slim/dp/B0CM9VHGY7/ref=sr_1_3?crid=3GOR693VEO69U&dib=eyJ2IjoiMSJ9.24sD8SdnVv-3aB5oHBS0Xg-wNRbkkttjoPJRofu3IBpRHCO0w-06laB77gEy8WiYVhqRP-fVdGes6kC5ZPVABiHVzJCQEFTxrky9NW-blNoVatZ1pPMUCOvgPanUPGxA6jbo63_7GByqIA0MAC75i5_MJ7c22zFi2vk5wsJ6ogGKqXL6zsUjY9ctD3TVpADH1ZcCMTEd4COQJ95Q0AVAQ8R_AqX3BEnxttt_eboVgGc.niIIzjtkhGZjZU7E8TDlZtG88NgF1zJhglL5FUjfQhw&dib_tag=se&keywords=playstation&qid=1716120758&sprefix=playstation%2Caps%2C778&sr=8-3&th=1'\n",
    "\n",
    "# Headers to mimic a real browser for the HTTP request\n",
    "headers = { \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0\", \n",
    "    \"Accept-Encoding\":\"gzip, deflate\", \n",
    "    \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \n",
    "    \"DNT\":\"1\",\n",
    "    \"Connection\":\"close\", \n",
    "    \"Upgrade-Insecure-Requests\":\"1\"\n",
    "}\n",
    "\n",
    "# Send a GET request to the URL with the specified headers\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Prettify the HTML content for better readability\n",
    "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlayStation 5 Console (Slim)\n",
      "£478.50\n",
      "1K+ bought in past month\n",
      "4.7 out of 5 stars\n"
     ]
    }
   ],
   "source": [
    "#Tested with other amazon domains such as .com and it was unable to fetch price so may need to loop through the price block htmls\n",
    "#Sometimes price and monthly_sales are not available due to item being sold out or not selling enough units\n",
    "\n",
    "title = None\n",
    "try:\n",
    "    title_span = soup2.find(\"span\", {\"id\": \"productTitle\"})\n",
    "    if title_span:\n",
    "        title = title_span.text.strip()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while extracting title: {e}\")\n",
    "\n",
    "price = None\n",
    "try:\n",
    "    price_span = soup2.find(\"span\", {\"class\": \"aok-offscreen\"})\n",
    "    if price_span:\n",
    "        price = price_span.text.strip()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while extracting price: {e}\")\n",
    "\n",
    "rating = None\n",
    "try:\n",
    "    rating_span = soup2.find(\"span\", {\"class\": \"a-icon-alt\"})\n",
    "    if rating_span:\n",
    "        rating = rating_span.text.strip()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while extracting rating: {e}\")\n",
    "\n",
    "monthly_sales = None\n",
    "try:\n",
    "    monthly_sales_span = soup2.find(\"span\", {\"id\": \"social-proofing-faceout-title-tk_bought\"})\n",
    "    if monthly_sales_span:\n",
    "        monthly_sales = monthly_sales_span.text.strip()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while extracting monthly sales: {e}\")\n",
    "\n",
    "print(title)\n",
    "print(price)\n",
    "print(monthly_sales)\n",
    "print(rating)\n",
    "#Amazon html for priceblock changed so found code on scarping dog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-19\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "today = datetime.datetime.now()\n",
    "print(today.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "header = [\"Title\", \"Price\", \"Monthly Sales\", \"Rating\", \"Date\"]\n",
    "rows = [title, price, monthly_sales, rating, today.strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "print(type(rows))  # Check to be a list because csv requires a list\n",
    "\n",
    "with open(\"AMZ_WebScrape_Dataset.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(rows)\n",
    "    \n",
    "#\"C:\\Users\\noaha\\AppData\\Local\\Programs\\Microsoft VS Code\\AMZ_WebScrape_Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title    Price             Monthly Sales  \\\n",
      "0  PlayStation 5 Console (Slim)  £478.50  1K+ bought in past month   \n",
      "\n",
      "               Rating        Date  \n",
      "0  4.7 out of 5 stars  2024-05-19  \n"
     ]
    }
   ],
   "source": [
    "#Seeing what the data will look like in a data frame \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"AMZ_WebScrape_Dataset.csv\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"AMZ_WebScrape_Dataset.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-19\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Temp\\ipykernel_26840\\217756761.py\", line 56, in <module>\n",
      "    time.sleep(5)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1134, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\noaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "           ^^^^^\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def check_price():\n",
    "    url = \"https://www.amazon.co.uk/Playstation-711719577157-PlayStation-Console-Slim/dp/B0CM9VHGY7/ref=sr_1_3?crid=3GOR693VEO69U&dib=eyJ2IjoiMSJ9.24sD8SdnVv-3aB5oHBS0Xg-wNRbkkttjoPJRofu3IBpRHCO0w-06laB77gEy8WiYVhqRP-fVdGes6kC5ZPVABiHVzJCQEFTxrky9NW-blNoVatZ1pPMUCOvgPanUPGxA6jbo63_7GByqIA0MAC75i5_MJ7c22zFi2vk5wsJ6ogGKqXL6zsUjY9ctD3TVpADH1ZcCMTEd4COQJ95Q0AVAQ8R_AqX3BEnxttt_eboVgGc.niIIzjtkhGZjZU7E8TDlZtG88NgF1zJhglL5FUjfQhw&dib_tag=se&keywords=playstation&qid=1716120758&sprefix=playstation%2Caps%2C778&sr=8-3&th=1\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    title = None\n",
    "    try:\n",
    "        title_span = soup.find(\"span\", {\"id\": \"productTitle\"})\n",
    "        if title_span:\n",
    "            title = title_span.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting title: {e}\")\n",
    "\n",
    "    price = None\n",
    "    try:\n",
    "        price_span = soup.find(\"span\", {\"class\": \"aok-offscreen\"})\n",
    "        if price_span:\n",
    "            price = price_span.text.strip()[1:]\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting price: {e}\")\n",
    "\n",
    "    rating = None\n",
    "    try:\n",
    "        rating_span = soup.find(\"span\", {\"class\": \"a-icon-alt\"})\n",
    "        if rating_span:\n",
    "            rating = rating_span.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting rating: {e}\")\n",
    "\n",
    "    monthly_sales = None\n",
    "    try:\n",
    "        monthly_sales_span = soup.find(\"span\", {\"id\": \"social-proofing-faceout-title-tk_bought\"})\n",
    "        if monthly_sales_span:\n",
    "            monthly_sales = monthly_sales_span.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting monthly sales: {e}\")\n",
    "        \n",
    "    today = datetime.datetime.now()\n",
    "    print(today.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    rows = [title, price, monthly_sales, rating, today.strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "\n",
    "    with open(\"AMZ_WebScrape_Dataset.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(rows)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86_400) #will automatically run this function every 24 hours /Automated if run in the background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"AMZ_WebScrape_Dataset.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow user to do a search for a specific item and select it , then send out an email to the user with the price of the item when it drops below a certain price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
